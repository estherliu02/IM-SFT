# torch==2.0.1
scipy
packaging
sentencepiece
datasets
deepspeed
# accelerate>=0.21.0,<0.23.0 
accelerate>=0.25.0
peft>=0.4.0, <0.8.2
bitsandbytes>=0.41.1
evaluate>=0.4.0
tokenizers>=0.13.3
protobuf
# Transformers library (v4.34.0) still has a bug for left padding, 
# and significantly affect the inference and thus our evaluation performance (e.g., MMLU and TruthfulQA).
# Follwing PR is a temporary fix for it but has not been merged yet.
# See https://github.com/huggingface/transformers/pull/25284
# But this PR is not compatible with the latest version of Transformers library (v4.34.0).
# To incorporate it, we forked the Transformers library and made some changes to make it compatible with the latest version.
#git+https://github.com/yizhongw/transformers.git@left_padding
transformers>=4.45.0,<=4.51.3,!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0; platform_system != 'Darwin'
#transformers==4.34.0; platform_system != 'Darwin'
# openai<=0.28.1
tiktoken
rouge_score
tensorboard
wandb
packaging
gradio==3.50.2
termcolor
jsonlines
unidic-lite
einops
flash-attn
auto-gptq
fire
alpaca-eval==0.5
# for human eval web app
flask
# vllm
openpyxl
# additional tools
wandb
huggingface_hub
liger-kernel